{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autoviz"
      ],
      "metadata": {
        "id": "2WaMWYEaMyFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "158351e4-7c02-411e-d478-fb6f384658a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autoviz\n",
            "  Downloading autoviz-0.1.905-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from autoviz) (2.0.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.9.4)\n",
            "Collecting emoji (from autoviz)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyamg (from autoviz)\n",
            "  Downloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.6.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.14.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from autoviz) (3.9.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.19.0)\n",
            "Collecting xgboost<1.7,>=0.82 (from autoviz)\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: fsspec>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from autoviz) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from autoviz) (4.12.2)\n",
            "Collecting pandas-dq>=1.29 (from autoviz)\n",
            "  Downloading pandas_dq-1.29-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.26.4)\n",
            "Collecting hvplot>=0.9.2 (from autoviz)\n",
            "  Downloading hvplot-0.11.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.20.1)\n",
            "Requirement already satisfied: panel>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (1.6.1)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from autoviz) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>3.7.4 in /usr/local/lib/python3.11/dist-packages (from autoviz) (3.10.0)\n",
            "Requirement already satisfied: seaborn>0.12.2 in /usr/local/lib/python3.11/dist-packages (from autoviz) (0.13.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.6.3)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (24.2)\n",
            "Requirement already satisfied: param<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews>=1.16.0->autoviz) (3.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.7.4->autoviz) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->autoviz) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->autoviz) (2025.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from panel>=1.4.0->autoviz) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->autoviz) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->autoviz) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->autoviz) (2024.11.6)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->autoviz) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (3.1.5)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh>=3.1->holoviews>=1.16.0->autoviz) (2025.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>3.7.4->autoviz) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.4.0->autoviz) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.4.0->autoviz) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.4.0->autoviz) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.4.0->autoviz) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.9->bokeh>=3.1->holoviews>=1.16.0->autoviz) (3.0.2)\n",
            "Downloading autoviz-0.1.905-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hvplot-0.11.2-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_dq-1.29-py3-none-any.whl (29 kB)\n",
            "Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyamg-5.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji, xgboost, pyamg, pandas-dq, hvplot, autoviz\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.4\n",
            "    Uninstalling xgboost-2.1.4:\n",
            "      Successfully uninstalled xgboost-2.1.4\n",
            "Successfully installed autoviz-0.1.905 emoji-2.14.1 hvplot-0.11.2 pandas-dq-1.29 pyamg-5.2.1 xgboost-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1y8b8SkUzwkW",
        "outputId": "cc901755-7d57-4d1b-dbf7-56482843e383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (600, 15)\n",
            "Missing Values:\n",
            " SSC_GPA                    0\n",
            "HSC_GPA                    3\n",
            "Family_Economy             0\n",
            "Residence                  0\n",
            "Family_Education           0\n",
            "Politics                   0\n",
            "Social_Media_Engagement    0\n",
            "Residence_with_Family      0\n",
            "Duration_of_Study          0\n",
            "College_Location           0\n",
            "School_Location            0\n",
            "Bad_Habits                 0\n",
            "Relationship               0\n",
            "External_Factors           0\n",
            "University                 0\n",
            "dtype: int64\n",
            "Duplicates: 95\n",
            "Target Distribution:\n",
            " University\n",
            "1    0.566667\n",
            "0    0.433333\n",
            "Name: proportion, dtype: float64\n",
            "          SSC_GPA     HSC_GPA  Family_Economy   Residence  Family_Education  \\\n",
            "count  600.000000  597.000000      600.000000  600.000000        600.000000   \n",
            "mean     4.853467    4.793032        2.673333    0.816667          0.866667   \n",
            "std      0.322999    0.382941        0.887657    0.387262          0.340218   \n",
            "min      2.990000    3.170000        1.000000    0.000000          0.000000   \n",
            "25%      4.890000    4.750000        2.000000    1.000000          1.000000   \n",
            "50%      5.000000    5.000000        3.000000    1.000000          1.000000   \n",
            "75%      5.000000    5.000000        3.000000    1.000000          1.000000   \n",
            "max      5.000000    5.000000        4.000000    1.000000          1.000000   \n",
            "\n",
            "         Politics  Social_Media_Engagement  Residence_with_Family  \\\n",
            "count  600.000000               600.000000             600.000000   \n",
            "mean     0.031667                 2.828333               0.633333   \n",
            "std      0.175257                 1.327328               0.482296   \n",
            "min      0.000000                 1.000000               0.000000   \n",
            "25%      0.000000                 1.000000               0.000000   \n",
            "50%      0.000000                 3.000000               1.000000   \n",
            "75%      0.000000                 4.000000               1.000000   \n",
            "max      1.000000                 5.000000               1.000000   \n",
            "\n",
            "       Duration_of_Study  College_Location  School_Location  Bad_Habits  \\\n",
            "count         600.000000        600.000000       600.000000  600.000000   \n",
            "mean            5.586667          0.906667         0.653333    0.066667   \n",
            "std             2.045188          0.291142         0.476306    0.249652   \n",
            "min             2.000000          0.000000         0.000000    0.000000   \n",
            "25%             4.000000          1.000000         0.000000    0.000000   \n",
            "50%             6.000000          1.000000         1.000000    0.000000   \n",
            "75%             8.000000          1.000000         1.000000    0.000000   \n",
            "max             8.000000          1.000000         1.000000    1.000000   \n",
            "\n",
            "       Relationship  External_Factors  University  \n",
            "count    600.000000        600.000000  600.000000  \n",
            "mean       0.231667          0.486667    0.566667  \n",
            "std        0.422249          0.500239    0.495949  \n",
            "min        0.000000          0.000000    0.000000  \n",
            "25%        0.000000          0.000000    0.000000  \n",
            "50%        0.000000          0.000000    1.000000  \n",
            "75%        0.000000          1.000000    1.000000  \n",
            "max        1.000000          1.000000    1.000000  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/refs/heads/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Basic exploration\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Missing Values:\\n\", df.isnull().sum())\n",
        "print(\"Duplicates:\", df.duplicated().sum())\n",
        "print(\"Target Distribution:\\n\", df['University'].value_counts(normalize=True))\n",
        "print(df.describe())\n",
        "\n",
        "# Visualize target distribution\n",
        "sns.countplot(x='University', data=df)\n",
        "plt.title(\"Admission Outcome Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Initialize AutoViz\n",
        "AV = AutoViz_Class()\n",
        "%matplotlib inline\n",
        "# Run AutoViz\n",
        "report = AV.AutoViz(\n",
        "    filename=\"\",  # Leave empty if using a DataFrame\n",
        "    dfte=df,      # Your DataFrame\n",
        "    chart_format=\"png\",  # Try \"svg\", \"png\", or \"jpg\"\n",
        "    verbose=0     # Try verbose=1 or 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5f0SM9gSPOZY",
        "outputId": "a59c188b-f130-48e8-f62f-d2c937eff1dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base"
      ],
      "metadata": {
        "id": "BR8tsoYwYofZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "WHNUgFnXZUku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer # Importing SimpleImputer to handle missing values\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/refs/heads/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "df['University'] = le.fit_transform(df['University'])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('University', axis=1)\n",
        "y = df['University']\n",
        "\n",
        "# Step 1: Handle missing values (impute with median)\n",
        "imputer = SimpleImputer(strategy='median')  # You can change to 'mean', 'most_frequent', or constant (e.g., fill_value=123)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns) # Imputing missing values with median\n",
        "\n",
        "# Step 3: Drop duplicates based on features\n",
        "df_combined = pd.concat([X_imputed, y], axis=1).drop_duplicates(subset=X_imputed.columns) # Using imputed data to drop duplicates\n",
        "X_clean = df_combined.drop('University', axis=1)\n",
        "y_clean = df_combined['University']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Training and Evaluation\n",
        "rf = RandomForestClassifier(random_state=42)  # You can tune hyperparameters here\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Tuned Test Accuracy\n",
        "tuned_test_accuracy = accuracy_score(y_test, rf.predict(X_test))\n",
        "print(f\"Tuned Test Accuracy: {tuned_test_accuracy}\")\n",
        "\n",
        "# Tuned Test ROC-AUC\n",
        "tuned_test_roc_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
        "print(f\"Tuned Test ROC-AUC: {tuned_test_roc_auc}\")\n",
        "\n",
        "# Full CV ROC-AUC (example using 5-fold cross-validation)\n",
        "cv_roc_auc = cross_val_score(rf, X_clean, y_clean, cv=5, scoring='roc_auc') # Using cleaned data for cross-validation\n",
        "print(f\"Full CV ROC-AUC: {np.mean(cv_roc_auc)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB9_0RMiN2-4",
        "outputId": "ac9b9acd-eb8c-44ef-8579-1e35dd940b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned Test Accuracy: 0.7878787878787878\n",
            "Tuned Test ROC-AUC: 0.8533057851239669\n",
            "Full CV ROC-AUC: 0.7891836734693877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Enginnering"
      ],
      "metadata": {
        "id": "1CLXiHW9ZW8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "4VLLqqugZZw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Your feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, y], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University']\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Optimized Random Forest (reduced depth, increased regularization)\n",
        "rf_final = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, min_samples_leaf=3, random_state=42)\n",
        "rf_final.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate test\n",
        "y_pred = rf_final.predict(X_test_scaled)\n",
        "y_prob = rf_final.predict_proba(X_test_scaled)[:, 1]\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "test_roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Final Test ROC-AUC: {test_roc_auc:.4f}\")\n",
        "\n",
        "# Cross-validation with 10 folds for stability\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(rf_final, X_fe_clean, y_clean, cv=cv, scoring='roc_auc')\n",
        "print(f\"10-Fold CV ROC-AUC: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD51PY-G1WYc",
        "outputId": "da3aabed-c0b6-485b-987f-e11b70795b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.7957\n",
            "Final Test ROC-AUC: 0.8609\n",
            "10-Fold CV ROC-AUC: 0.8647 (±0.0477)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest- ADABoost - XGBoost Comparison"
      ],
      "metadata": {
        "id": "MleEDPhMZkqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier  # For AdaBoost base estimator\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, y], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University']\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Optimized Random Forest (for comparison)\n",
        "rf_final = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, min_samples_leaf=3, random_state=42)\n",
        "rf_final.fit(X_train_scaled, y_train)\n",
        "# Evaluate Random Forest (for comparison)\n",
        "rf_pred = rf_final.predict(X_test_scaled)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_final.predict_proba(X_test_scaled)[:, 1], multi_class='ovr')  # Multiclass adjustment\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest Test ROC-AUC (OvR): {rf_roc_auc:.4f}\")\n",
        "\n",
        "# AdaBoost Classifier\n",
        "# Using a decision tree with max_depth=1 as the base estimator (default for AdaBoost)\n",
        "ada = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),  # Weak learner\n",
        "    n_estimators=200,  # Number of boosting rounds\n",
        "    learning_rate=0.5,  # Default learning rate\n",
        "    random_state=42\n",
        ")\n",
        "ada.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate AdaBoost\n",
        "ada_pred = ada.predict(X_test_scaled)\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "ada_probs = ada.predict_proba(X_test_scaled)[:, 1]  # Probabilities for class 1\n",
        "ada_roc_auc = roc_auc_score(y_test, ada_probs, multi_class='ovr')  # Multiclass adjustment\n",
        "\n",
        "print(f\"AdaBoost Test Accuracy: {ada_accuracy:.4f}\")\n",
        "print(f\"AdaBoost Test ROC-AUC (OvR): {ada_roc_auc:.4f}\")\n",
        "\n",
        "# Cross-validation for AdaBoost (10-fold)\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "ada_cv_scores = cross_val_score(ada, X_fe_clean, y_clean, cv=cv, scoring='roc_auc_ovr')  # Multiclass adjustment\n",
        "print(f\"AdaBoost 10-Fold CV ROC-AUC (OvR): {ada_cv_scores.mean():.4f} (±{ada_cv_scores.std():.4f})\")\n",
        "\n",
        "# XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',  # Multiclass classification with probabilities\n",
        "    num_class=len(np.unique(y_clean)),  # Number of unique classes in y\n",
        "    n_estimators=50,  # Number of trees\n",
        "    max_depth=3,  # Maximum depth of trees\n",
        "    learning_rate=0.1,  # Step size shrinkage\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'  # Multiclass log loss for evaluation\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate XGBoost\n",
        "# Get predicted probabilities for each class\n",
        "xgb_probs = xgb_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Get class labels with the highest probability (argmax)\n",
        "xgb_pred = np.argmax(xgb_probs, axis=1)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "xgb_probs_positive_class = xgb_probs[:, 1]  # Select probabilities for class 1 only\n",
        "\n",
        "# Calculate ROC-AUC for binary classification (using probabilities for positive class)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_probs_positive_class)  # No need for multi_class='ovr'\n",
        "\n",
        "print(f\"XGBoost Test Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"XGBoost Test ROC-AUC: {xgb_roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd4uFK8HQ2bM",
        "outputId": "bcc2b508-a9b4-46cf-eb6d-69ce282c66fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 0.7957\n",
            "Random Forest Test ROC-AUC (OvR): 0.8609\n",
            "AdaBoost Test Accuracy: 0.7957\n",
            "AdaBoost Test ROC-AUC (OvR): 0.8484\n",
            "AdaBoost 10-Fold CV ROC-AUC (OvR): 0.8571 (±0.0537)\n",
            "XGBoost Test Accuracy: 0.8065\n",
            "XGBoost Test ROC-AUC: 0.8484\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
        "    'estimator__max_depth': [1, 2, 3]  # Changed 'base_estimator__' to 'estimator__'\n",
        "}\n",
        "ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=42) # Changed 'base_estimator' to 'estimator'\n",
        "grid_search = GridSearchCV(ada, param_grid, cv=5, scoring='roc_auc_ovr', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print(f\"Best Params: {grid_search.best_params_}\")\n",
        "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sc8JyUtRYeW",
        "outputId": "1b339e8a-f084-41e0-f9b3-5d78ae69b543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'estimator__max_depth': 1, 'learning_rate': 0.5, 'n_estimators': 200}\n",
            "Best CV ROC-AUC: 0.8596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest- ADABoost - Tuned XGBoost Comparison"
      ],
      "metadata": {
        "id": "smGIsSi5dy7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "\n",
        "# Encode target for XGBoost (XGBoost requires numeric labels starting from 0)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)  # Convert University to numeric labels\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, pd.Series(y, name='University')], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University']\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Evaluate Random Forest (for comparison)\n",
        "rf_pred = rf_final.predict(X_test_scaled)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "rf_probs = rf_final.predict_proba(X_test_scaled)[:, 1]  # Select probabilities for class 1 only\n",
        "# Calculate ROC-AUC for binary classification\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_probs)  # No need for multi_class='ovr' for binary case\n",
        "\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest Test ROC-AUC: {rf_roc_auc:.4f}\")\n",
        "\n",
        "# Tuned AdaBoost (for comparison)\n",
        "ada_tuned = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "ada_tuned.fit(X_train_scaled, y_train)\n",
        "# Evaluate AdaBoost\n",
        "ada_pred = ada_tuned.predict(X_test_scaled)\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "ada_probs = ada_tuned.predict_proba(X_test_scaled)[:, 1]  # Probabilities for class 1 only\n",
        "\n",
        "# Calculate ROC-AUC for binary classification\n",
        "ada_roc_auc = roc_auc_score(y_test, ada_probs)  # No need for multi_class='ovr' for binary case\n",
        "\n",
        "print(f\"AdaBoost Test Accuracy: {ada_accuracy:.4f}\")\n",
        "print(f\"AdaBoost Test ROC-AUC: {ada_roc_auc:.4f}\")\n",
        "\n",
        "# XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',  # Multiclass classification with probabilities\n",
        "    num_class=len(np.unique(y_clean)),  # Number of unique classes in y\n",
        "    n_estimators=100,  # Number of trees\n",
        "    max_depth=6,  # Maximum depth of trees\n",
        "    learning_rate=0.1,  # Step size shrinkage\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'  # Multiclass log loss for evaluation\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate XGBoost\n",
        "# Get predicted probabilities for each class\n",
        "xgb_probs = xgb_model.predict_proba(X_test_scaled)\n",
        "\n",
        "# Get class labels with the highest probability (argmax)\n",
        "xgb_pred = np.argmax(xgb_probs, axis=1)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "\n",
        "# Get probabilities for the positive class (assuming class 1 is positive)\n",
        "xgb_probs_positive_class = xgb_probs[:, 1]  # Select probabilities for class 1 only\n",
        "\n",
        "# Calculate ROC-AUC for binary classification (using probabilities for positive class)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_probs_positive_class)  # No need for multi_class='ovr'\n",
        "\n",
        "print(f\"XGBoost Test Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"XGBoost Test ROC-AUC: {xgb_roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdyAmEaCZzu8",
        "outputId": "8fc1b775-914f-428f-d785-ad9a0e5bd84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 0.7957\n",
            "Random Forest Test ROC-AUC: 0.8609\n",
            "AdaBoost Test Accuracy: 0.7957\n",
            "AdaBoost Test ROC-AUC: 0.8484\n",
            "XGBoost Test Accuracy: 0.8387\n",
            "XGBoost Test ROC-AUC: 0.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "A1JY4RcSwLOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Robust Scalar Without the Outliers"
      ],
      "metadata": {
        "id": "BSBkD_bMyKPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, pd.Series(y, name='University')], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University'].values.ravel()\n",
        "\n",
        "# Cap outliers\n",
        "continuous_features = ['Average_GPA', 'GPA_Diff', 'Study_Efficiency', 'Social_Impact', 'Family_Support', 'Study_Social_Ratio']\n",
        "for col in continuous_features:\n",
        "    Q1 = X_fe_clean[col].quantile(0.25)\n",
        "    Q3 = X_fe_clean[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers_before = ((X_fe_clean[col] < lower_bound) | (X_fe_clean[col] > upper_bound)).sum()\n",
        "    X_fe_clean[col] = X_fe_clean[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "    print(f\"Capped {outliers_before} outliers in {col}. Rows remain: {len(X_fe_clean)}\")\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf_final = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=5, min_samples_leaf=3, random_state=42)\n",
        "rf_final.fit(X_train_scaled, y_train)\n",
        "rf_pred = rf_final.predict(X_test_scaled)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "rf_probs = rf_final.predict_proba(X_test_scaled)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_probs[:, 1])  # Binary ROC-AUC\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Random Forest Test ROC-AUC: {rf_roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "25QbSskwiieI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96e5d54-14a6-473b-9e57-f277f583968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capped 29 outliers in Average_GPA. Rows remain: 461\n",
            "Capped 131 outliers in GPA_Diff. Rows remain: 461\n",
            "Capped 0 outliers in Study_Efficiency. Rows remain: 461\n",
            "Capped 0 outliers in Social_Impact. Rows remain: 461\n",
            "Capped 27 outliers in Family_Support. Rows remain: 461\n",
            "Capped 86 outliers in Study_Social_Ratio. Rows remain: 461\n",
            "Random Forest Test Accuracy: 0.8065\n",
            "Random Forest Test ROC-AUC: 0.8633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADABoost\n"
      ],
      "metadata": {
        "id": "ZyzFGFq_wNoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard Scaler With the Outliers"
      ],
      "metadata": {
        "id": "3JuVqVf0zBaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, pd.Series(y, name='University')], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University'].values.ravel()\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Tuned AdaBoost\n",
        "ada_tuned = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "ada_tuned.fit(X_train_scaled, y_train)\n",
        "ada_pred = ada_tuned.predict(X_test_scaled)\n",
        "ada_accuracy = accuracy_score(y_test, ada_pred)\n",
        "ada_probs = ada_tuned.predict_proba(X_test_scaled)\n",
        "ada_roc_auc = roc_auc_score(y_test, ada_probs[:, 1])\n",
        "print(f\"AdaBoost Test Accuracy: {ada_accuracy:.4f}\")\n",
        "print(f\"AdaBoost Test ROC-AUC (OvR): {ada_roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "tECazZ6PwPnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e380e3e-1453-4288-da73-b92d4eb712e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Test Accuracy: 0.7957\n",
            "AdaBoost Test ROC-AUC (OvR): 0.8484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "8NPitM38wRsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard Scaler with the Outliers"
      ],
      "metadata": {
        "id": "pg2RVvO_zUwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/Ashfinn/admission-feature-analysis/main/Undergraduate%20Admission%20Test%20Survey%20in%20Bangladesh.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['University'])\n",
        "y = df['University']\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "X = pd.get_dummies(X, columns=['Residence'], drop_first=True)\n",
        "\n",
        "# Feature engineering\n",
        "X_fe = X.copy()\n",
        "X_fe['Average_GPA'] = (X_fe['SSC_GPA'] + X_fe['HSC_GPA']) / 2\n",
        "X_fe['GPA_Diff'] = X_fe['HSC_GPA'] - X_fe['SSC_GPA']\n",
        "X_fe['Study_Efficiency'] = X_fe['Duration_of_Study'] / X_fe['Average_GPA'].replace(0, 1e-6)\n",
        "X_fe['Social_Impact'] = X_fe['Social_Media_Engagement'] * X_fe['Average_GPA']\n",
        "X_fe['Family_Support'] = X_fe['Family_Economy'] + X_fe['Family_Education']\n",
        "X_fe['Study_Social_Ratio'] = X_fe['Duration_of_Study'] / X_fe['Social_Media_Engagement'].replace(0, 1e-6)\n",
        "X_fe = X_fe.drop(columns=['SSC_GPA', 'HSC_GPA', 'Social_Media_Engagement', 'External_Factors', 'Politics', 'Duration_of_Study', 'Family_Education'])\n",
        "\n",
        "# Clean duplicates\n",
        "df_combined = pd.concat([X_fe, pd.Series(y, name='University')], axis=1).drop_duplicates(subset=X_fe.columns)\n",
        "X_fe_clean = df_combined.drop(columns=['University'])\n",
        "y_clean = df_combined['University'].values.ravel()\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean)\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',  # Multiclass classification with probabilities\n",
        "    num_class=len(np.unique(y_clean)),  # Number of unique classes in y\n",
        "    n_estimators=100,  # Number of trees\n",
        "    max_depth=6,  # Maximum depth of trees\n",
        "    learning_rate=0.1,  # Step size shrinkage\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'  # Multiclass log loss for evaluation\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get predicted probabilities for each class\n",
        "xgb_probs = xgb_model.predict_proba(X_test_scaled)\n",
        "# Get class labels with the highest probability (argmax)\n",
        "xgb_pred = np.argmax(xgb_probs, axis=1) # Get predicted class labels instead of probabilities\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)  # Now using predicted labels\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_probs[:, 1])  # Using probabilities for ROC AUC\n",
        "print(f\"XGBoost Test Accuracy: {xgb_accuracy:.4f}\")\n",
        "print(f\"XGBoost Test ROC-AUC (OvR): {xgb_roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwIBI4RWfdeR",
        "outputId": "8bbaeba1-2f0d-4e8e-e6ae-28b39d88108b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Test Accuracy: 0.8387\n",
            "XGBoost Test ROC-AUC (OvR): 0.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JglVA1-1jAzh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}